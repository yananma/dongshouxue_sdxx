
### 等同视之，就是都不重要，要抓住主要矛盾，要使用注意力机制。李航这本书抄了 9 遍，半年时间，用了十几支笔，结果还是一头雾水。现在找了最重要的 20 个公式，几天就完全掌握了，效率差 1000 倍，效果更好。

每天起床第一件事就是公式，用抄公式学会机器学习    
现在抄公式的目的是面试，所以方法应该是广而浅，能答上来就行，一般不超过 10 遍，面试前再抄一遍。如果工作之后用的算法还有不熟练的地方，再专而深，有的是时间，来日方长。  
### 抄公式半个小时就行，一天 2 个，一天 3 次，两到三天完成一个公式  
SVM 第 11 遍；读周志华、李航，最后整合 1 遍  
GBDT 读公式读例题 3 遍  
xgboost 公式 9 遍  
LSTM 公式 12 遍，读图画图 4 遍   
梯度消失梯度爆炸公式 1 遍  
Kmeans 读 20 遍 10 次     
TF-IDF 公式读 20 遍 6 次  
word2vec 公式  
Batch Norm 公式读  次    
大 O 读  遍  
交叉熵损失函数读 d2l  遍  
nndl 注意力机制公式    

成不了最聪明的人，但是可以成为抄公式最多的人。  

抄公式，付出极少，收获极大，极为有效  

这个是关键所在，总是记不住，抄个百八十遍肯定就记住了。赫布理论、听歌、卖油翁  

抄很多遍，抄 100 遍还还记不住？再记不住就抄 1000 遍  

要背诵一些基础知识点，否则一直浮于表面，细节不清晰，用的时候力不从心  

理解了的道理而没有牢记下来就不能称其为知识————但丁《神曲》  

就可劲儿抄去吧，这是最容易，最轻松的事了，很享受这个过程，就是一种休息    

这个方法可以有效弥补自己只观大略造成的根不深，细节不清晰的问题，又极为简单，所以极好  

重要公式：

P14 贝叶斯公式  
P35 (2.1) 感知机模型  
P50 (3.1) K 近邻模型  
P62 算法 4.1 和例 4.1. 朴素贝叶斯算法；每次抄一遍就行，抄很多次  

#### 《决策树》
P73 自己的笔记，(5.5)条件熵；理解了熵和条件熵就掌握了决策树和集成算法的核心内容，看例题公式就清清楚楚  
P74 算法 5.1  
P75 例 5.2  
P76 信息增益比  
P82 算法 5.5，结合 P168 例 8.2  
P83 基尼指数 (5.22)(5.24)(5.25)  

P90 LR 公式  

P156 算法 8.1 (Adaboost)  
P158 例 8.1 Adaboost 例题(读)  
P166 提升树  
P168 例 8.2  
P171 算法 8.4 (GBDT)  

P264 Kmeans 公式；两句话是核心，背下来    
P265 算法 14.2 (Kmeans)  
P267 K 值的选择  

P320 TF-IDF 自己写的公式和上面的总结的一句话  

要抄写的内容：面试常问的问题、李航统计学习方法、周志华机器学习、论文、  


已完成公式，所有的都过完一遍之后，再精通。面试之前再抄一遍  

LR 公式 13 遍  

xgboost 视频《Python 数据分析与机器学习实战》 200、201、204 看完第 2 遍  


#### 知识点：
Kmeans 具体步骤：  
1、随机选择 k 个样本点作为初始聚类中心  
2、计算每个样本到类中心的距离，将每个样本指派到与其最近的中心的类中，得到一个聚类结果  
3、更新每个类的样本的均值，作为类的新的中心  
4、重复上面两个步骤，直到收敛为止  

六个字：定中心，分样本  


