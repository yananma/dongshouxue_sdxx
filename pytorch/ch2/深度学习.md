

### 重要问题  

### 解决这些问题的工具：抄公式、pysnooper、读论文、用搜索引擎、  

#### Batch Norm  

#### RNN 原理，RNN 为什么难以训练，

#### LSTM 是怎么改进的，LSTM有几个门？各个门的作用是什么？公式是什么？LSTM解决了什么问题、画一下LSTM结构图、

#### 说一说 word embedding、word2vec、skip-gram、

#### Mask R-CNN
损失函数、RPN、ROIAlign、

#### ResNet
resnet优点特点、短路连接作用、


### 一般问题  

1、要 pysnooper 3 个优化器，SGD、动量法、Adam  
d2l 第 7 章  

2、momentum 等优化算法公式，参数含义  

3、输入n*n*1，卷积和k*k*6， 问输出尺寸和参数量（nndl，弄懂卷积神经网络参数是什么）  

4、VGG优点，resnet优点特点（d2l）  

5、relu 好处  

6、


### 已解决问题

#### numpy 实现卷积  
d2l 和鱼书，还是以 d2l 为准  

#### 激活函数
d2l 面试前再读一遍 3.8 节  

#### 1x1卷积核作用
改变通道数  

#### Dropout 的作用
在训练中，隐藏层神经元的丢弃是随机的，输入层的计算无法过度依赖任何一个，从而在训练中起到正则化的作用，可以用来有效应对过拟合。  
Hinton 去银行想打的，如果一直是这些职员，那么就有可能和劫匪或者做假账的串通。经常随机调换，就不会有这个问题。  


#### 梯度消失、梯度爆炸的原因，应该是层数太多了，看书确认一下







