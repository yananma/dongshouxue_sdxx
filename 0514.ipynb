{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "0514.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/yananma/5_programs_per_day/blob/master/0514.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bhQlMhL9EuSZ",
        "colab_type": "text"
      },
      "source": [
        "## 9.12 实战 Kaggle 比赛：图像分类 ( CIFAR-10 )"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xPSXCo4yFPMP",
        "colab_type": "code",
        "outputId": "6a940bdb-63b6-4cf8-ef4d-65e951cd5578",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "!pip install mxnet d2lzh"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting mxnet\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/92/6c/c6e5562f8face683cec73f5d4d74a58f8572c0595d54f1fed9d923020bbd/mxnet-1.5.1.post0-py2.py3-none-manylinux1_x86_64.whl (25.4MB)\n",
            "\u001b[K     |████████████████████████████████| 25.4MB 31.7MB/s \n",
            "\u001b[?25hCollecting d2lzh\n",
            "  Downloading https://files.pythonhosted.org/packages/21/cd/a5dbf74fce1a2b0a805488065135a753b4419b29cce109dee960824f1468/d2lzh-0.8.11.tar.gz\n",
            "Requirement already satisfied: numpy<2.0.0,>1.16.0 in /usr/local/lib/python3.6/dist-packages (from mxnet) (1.17.4)\n",
            "Collecting graphviz<0.9.0,>=0.8.1\n",
            "  Downloading https://files.pythonhosted.org/packages/53/39/4ab213673844e0c004bed8a0781a0721a3f6bb23eb8854ee75c236428892/graphviz-0.8.4-py2.py3-none-any.whl\n",
            "Requirement already satisfied: requests<3,>=2.20.0 in /usr/local/lib/python3.6/dist-packages (from mxnet) (2.21.0)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.6/dist-packages (from d2lzh) (3.1.1)\n",
            "Requirement already satisfied: jupyter in /usr/local/lib/python3.6/dist-packages (from d2lzh) (1.0.0)\n",
            "Requirement already satisfied: urllib3<1.25,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.20.0->mxnet) (1.24.3)\n",
            "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.20.0->mxnet) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.20.0->mxnet) (2019.9.11)\n",
            "Requirement already satisfied: idna<2.9,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.20.0->mxnet) (2.8)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->d2lzh) (1.1.0)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->d2lzh) (2.4.5)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->d2lzh) (2.6.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.6/dist-packages (from matplotlib->d2lzh) (0.10.0)\n",
            "Requirement already satisfied: nbconvert in /usr/local/lib/python3.6/dist-packages (from jupyter->d2lzh) (5.6.1)\n",
            "Requirement already satisfied: qtconsole in /usr/local/lib/python3.6/dist-packages (from jupyter->d2lzh) (4.6.0)\n",
            "Requirement already satisfied: notebook in /usr/local/lib/python3.6/dist-packages (from jupyter->d2lzh) (5.2.2)\n",
            "Requirement already satisfied: ipykernel in /usr/local/lib/python3.6/dist-packages (from jupyter->d2lzh) (4.6.1)\n",
            "Requirement already satisfied: ipywidgets in /usr/local/lib/python3.6/dist-packages (from jupyter->d2lzh) (7.5.1)\n",
            "Requirement already satisfied: jupyter-console in /usr/local/lib/python3.6/dist-packages (from jupyter->d2lzh) (5.2.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from kiwisolver>=1.0.1->matplotlib->d2lzh) (41.6.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.6/dist-packages (from python-dateutil>=2.1->matplotlib->d2lzh) (1.12.0)\n",
            "Requirement already satisfied: nbformat>=4.4 in /usr/local/lib/python3.6/dist-packages (from nbconvert->jupyter->d2lzh) (4.4.0)\n",
            "Requirement already satisfied: pandocfilters>=1.4.1 in /usr/local/lib/python3.6/dist-packages (from nbconvert->jupyter->d2lzh) (1.4.2)\n",
            "Requirement already satisfied: defusedxml in /usr/local/lib/python3.6/dist-packages (from nbconvert->jupyter->d2lzh) (0.6.0)\n",
            "Requirement already satisfied: traitlets>=4.2 in /usr/local/lib/python3.6/dist-packages (from nbconvert->jupyter->d2lzh) (4.3.3)\n",
            "Requirement already satisfied: jupyter-core in /usr/local/lib/python3.6/dist-packages (from nbconvert->jupyter->d2lzh) (4.6.1)\n",
            "Requirement already satisfied: testpath in /usr/local/lib/python3.6/dist-packages (from nbconvert->jupyter->d2lzh) (0.4.4)\n",
            "Requirement already satisfied: pygments in /usr/local/lib/python3.6/dist-packages (from nbconvert->jupyter->d2lzh) (2.1.3)\n",
            "Requirement already satisfied: bleach in /usr/local/lib/python3.6/dist-packages (from nbconvert->jupyter->d2lzh) (3.1.0)\n",
            "Requirement already satisfied: entrypoints>=0.2.2 in /usr/local/lib/python3.6/dist-packages (from nbconvert->jupyter->d2lzh) (0.3)\n",
            "Requirement already satisfied: jinja2>=2.4 in /usr/local/lib/python3.6/dist-packages (from nbconvert->jupyter->d2lzh) (2.10.3)\n",
            "Requirement already satisfied: mistune<2,>=0.8.1 in /usr/local/lib/python3.6/dist-packages (from nbconvert->jupyter->d2lzh) (0.8.4)\n",
            "Requirement already satisfied: ipython-genutils in /usr/local/lib/python3.6/dist-packages (from qtconsole->jupyter->d2lzh) (0.2.0)\n",
            "Requirement already satisfied: jupyter-client>=4.1 in /usr/local/lib/python3.6/dist-packages (from qtconsole->jupyter->d2lzh) (5.3.4)\n",
            "Requirement already satisfied: tornado>=4 in /usr/local/lib/python3.6/dist-packages (from notebook->jupyter->d2lzh) (4.5.3)\n",
            "Requirement already satisfied: terminado>=0.3.3; sys_platform != \"win32\" in /usr/local/lib/python3.6/dist-packages (from notebook->jupyter->d2lzh) (0.8.3)\n",
            "Requirement already satisfied: ipython>=4.0.0 in /usr/local/lib/python3.6/dist-packages (from ipykernel->jupyter->d2lzh) (5.5.0)\n",
            "Requirement already satisfied: widgetsnbextension~=3.5.0 in /usr/local/lib/python3.6/dist-packages (from ipywidgets->jupyter->d2lzh) (3.5.1)\n",
            "Requirement already satisfied: prompt-toolkit<2.0.0,>=1.0.0 in /usr/local/lib/python3.6/dist-packages (from jupyter-console->jupyter->d2lzh) (1.0.18)\n",
            "Requirement already satisfied: jsonschema!=2.5.0,>=2.4 in /usr/local/lib/python3.6/dist-packages (from nbformat>=4.4->nbconvert->jupyter->d2lzh) (2.6.0)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.6/dist-packages (from traitlets>=4.2->nbconvert->jupyter->d2lzh) (4.4.1)\n",
            "Requirement already satisfied: webencodings in /usr/local/lib/python3.6/dist-packages (from bleach->nbconvert->jupyter->d2lzh) (0.5.1)\n",
            "Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.6/dist-packages (from jinja2>=2.4->nbconvert->jupyter->d2lzh) (1.1.1)\n",
            "Requirement already satisfied: pyzmq>=13 in /usr/local/lib/python3.6/dist-packages (from jupyter-client>=4.1->qtconsole->jupyter->d2lzh) (17.0.0)\n",
            "Requirement already satisfied: ptyprocess; os_name != \"nt\" in /usr/local/lib/python3.6/dist-packages (from terminado>=0.3.3; sys_platform != \"win32\"->notebook->jupyter->d2lzh) (0.6.0)\n",
            "Requirement already satisfied: pickleshare in /usr/local/lib/python3.6/dist-packages (from ipython>=4.0.0->ipykernel->jupyter->d2lzh) (0.7.5)\n",
            "Requirement already satisfied: simplegeneric>0.8 in /usr/local/lib/python3.6/dist-packages (from ipython>=4.0.0->ipykernel->jupyter->d2lzh) (0.8.1)\n",
            "Requirement already satisfied: pexpect; sys_platform != \"win32\" in /usr/local/lib/python3.6/dist-packages (from ipython>=4.0.0->ipykernel->jupyter->d2lzh) (4.7.0)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.6/dist-packages (from prompt-toolkit<2.0.0,>=1.0.0->jupyter-console->jupyter->d2lzh) (0.1.7)\n",
            "Building wheels for collected packages: d2lzh\n",
            "  Building wheel for d2lzh (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for d2lzh: filename=d2lzh-0.8.11-cp36-none-any.whl size=10011 sha256=812d15a9e554e20260fd64ecaa801728c7e70762c9195a4c81e6fff6ec3a68ae\n",
            "  Stored in directory: /root/.cache/pip/wheels/bb/4a/3e/81075d0b470000f4b5769c936f64b22be31c6bcfa81fd050d6\n",
            "Successfully built d2lzh\n",
            "Installing collected packages: graphviz, mxnet, d2lzh\n",
            "  Found existing installation: graphviz 0.10.1\n",
            "    Uninstalling graphviz-0.10.1:\n",
            "      Successfully uninstalled graphviz-0.10.1\n",
            "Successfully installed d2lzh-0.8.11 graphviz-0.8.4 mxnet-1.5.1.post0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q-VMqJLvFqPB",
        "colab_type": "code",
        "outputId": "39257f22-7408-46e9-ddac-4e6f5c57efe5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 151
        }
      },
      "source": [
        "!git clone https://www.github.com/d2l-ai/d2l-zh.git"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'd2l-zh'...\n",
            "warning: redirecting to https://github.com/d2l-ai/d2l-zh.git/\n",
            "remote: Enumerating objects: 17, done.\u001b[K\n",
            "remote: Counting objects:   5% (1/17)\u001b[K\rremote: Counting objects:  11% (2/17)\u001b[K\rremote: Counting objects:  17% (3/17)\u001b[K\rremote: Counting objects:  23% (4/17)\u001b[K\rremote: Counting objects:  29% (5/17)\u001b[K\rremote: Counting objects:  35% (6/17)\u001b[K\rremote: Counting objects:  41% (7/17)\u001b[K\rremote: Counting objects:  47% (8/17)\u001b[K\rremote: Counting objects:  52% (9/17)\u001b[K\rremote: Counting objects:  58% (10/17)\u001b[K\rremote: Counting objects:  64% (11/17)\u001b[K\rremote: Counting objects:  70% (12/17)\u001b[K\rremote: Counting objects:  76% (13/17)\u001b[K\rremote: Counting objects:  82% (14/17)\u001b[K\rremote: Counting objects:  88% (15/17)\u001b[K\rremote: Counting objects:  94% (16/17)\u001b[K\rremote: Counting objects: 100% (17/17)\u001b[K\rremote: Counting objects: 100% (17/17), done.\u001b[K\n",
            "remote: Compressing objects: 100% (13/13), done.\u001b[K\n",
            "remote: Total 15702 (delta 9), reused 8 (delta 4), pack-reused 15685\u001b[K\n",
            "Receiving objects: 100% (15702/15702), 159.56 MiB | 32.91 MiB/s, done.\n",
            "Resolving deltas: 100% (11132/11132), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1BI1r12zGpTY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!mkdir ../data"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rApH6ST8HV0F",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!cp -r ./d2l-zh/data/kaggle_cifar10/ ../data/"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o4om-_iVIfT2",
        "colab_type": "code",
        "outputId": "1a29f51c-762d-46e6-9ea6-e3fb855c876e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "!ls ../data/kaggle_cifar10/"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "test_tiny.zip  trainLabels.csv.zip  train_tiny.zip\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PjinGnDoJeck",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import d2lzh as d2l \n",
        "from mxnet import autograd, gluon, init \n",
        "from mxnet.gluon import data as gdata, loss as gloss, nn \n",
        "import os \n",
        "import pandas as pd \n",
        "import shutil \n",
        "import time "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JjADZZauJyR9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "demo = True \n",
        "if demo:\n",
        "    import zipfile \n",
        "    for f in ['train_tiny.zip', 'test_tiny.zip', 'trainLabels.csv.zip']:\n",
        "        with zipfile.ZipFile('../data/kaggle_cifar10/' + f, 'r') as z:\n",
        "            z.extractall('../data/kaggle_cifar10/')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G3lh-8uGK2PF",
        "colab_type": "code",
        "outputId": "c788af54-6fbc-4c17-89a7-81f9d065305c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        }
      },
      "source": [
        "!ls ../data/kaggle_cifar10/"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "test_tiny      trainLabels.csv\t    train_tiny\n",
            "test_tiny.zip  trainLabels.csv.zip  train_tiny.zip\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B-e2kVpOLF_t",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def read_label_file(data_dir, label_file, train_dir, valid_ratio):\n",
        "    with open(os.path.join(data_dir, label_file), 'r') as f:\n",
        "        lines = f.readlines()[1:]\n",
        "        tokens = [l.rstrip().split(',') for l in lines] \n",
        "        idx_label = dict(((int(idx), label) for idx, label in tokens))\n",
        "    labels = set(idx_label.values())\n",
        "    n_train_valid = len(os.listdir(os.path.join(data_dir, train_dir)))\n",
        "    n_train = int(n_train_valid * (1 - valid_ratio))\n",
        "    assert 0 < n_train < n_train_valid \n",
        "    return n_train // len(labels), idx_label "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Bz38DnLVMITO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def mkdir_if_not_exist(path):\n",
        "    if not os.path.exists(os.path.join(*path)):\n",
        "        os.makedirs(os.path.join(*path))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vXAR6sGtMuEs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def reorg_train_valid(data_dir, train_dir, input_dir, n_train_per_label, idx_label):\n",
        "    label_count = {}\n",
        "    for train_file in os.listdir(os.path.join(data_dir, train_dir)):\n",
        "        idx = int(train_file.split('.')[0])\n",
        "        label = idx_label[idx]\n",
        "        mkdir_if_not_exist([data_dir, input_dir, 'train_valid', label])\n",
        "        shutil.copy(os.path.join(data_dir, train_dir, train_file), \n",
        "              os.path.join(data_dir, input_dir, 'train_valid', label))\n",
        "        if label not in label_count or label_count[label] < n_train_per_label:\n",
        "            mkdir_if_not_exist([data_dir, input_dir, 'train', label])\n",
        "            shutil.copy(os.path.join(data_dir, train_dir, train_file), \n",
        "                os.path.join(data_dir, input_dir, 'train', label))\n",
        "            label_count[label] = label_count.get(label, 0) + 1 \n",
        "        else:\n",
        "            mkdir_if_not_exist([data_dir, input_dir, 'valid', label])\n",
        "            shutil.copy(os.path.join(data_dir, train_dir, train_file), \n",
        "                  os.path.join(data_dir, input_dir, 'valid', label))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eO8nnH5YRkFs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def reorg_test(data_dir, test_dir, input_dir):\n",
        "    mkdir_if_not_exist([data_dir, input_dir, 'test', 'unknown'])\n",
        "    for test_file in os.listdir(os.path.join(data_dir, test_dir)):\n",
        "        shutil.copy(os.path.join(data_dir, test_dir, test_file), \n",
        "              os.path.join(data_dir, input_dir, 'test', 'unknown'))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6levJJ8gSc5q",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def reorg_cifar10_data(data_dir, label_file, train_dir, test_dir, input_dir, valid_ratio):\n",
        "    n_train_per_label, idx_label = read_label_file(data_dir, label_file, train_dir, valid_ratio)\n",
        "    reorg_train_valid(data_dir, train_dir, input_dir, n_train_per_label, idx_label)\n",
        "    reorg_test(data_dir, test_dir, input_dir)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A_TSKHfEfVyp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "if demo:\n",
        "    train_dir, test_dir, batch_size = 'train_tiny', 'test_tiny', 1\n",
        "else:\n",
        "    train_dir, test_dir, batch_size = 'train', 'test', 128 \n",
        "data_dir, label_file = '../data/kaggle_cifar10', 'trainLabels.csv'\n",
        "input_dir, valid_ratio = 'train_valid_test', 0.1\n",
        "reorg_cifar10_data(data_dir, label_file, train_dir, test_dir, input_dir, valid_ratio)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NFxNG8U8gmQG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "transform_train = gdata.vision.transforms.Compose([\n",
        "    gdata.vision.transforms.Resize(40), \n",
        "    gdata.vision.transforms.RandomResizedCrop(32, scale=(0.64, 1.0), ratio=(1.0, 1.0)),\n",
        "    gdata.vision.transforms.RandomFlipLeftRight(), \n",
        "    gdata.vision.transforms.ToTensor(), \n",
        "    gdata.vision.transforms.Normalize([0.4914, 0.4822, 0.4465], [0.2023, 0.1194, 0.2010])\n",
        "])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GpsUDIRnjwku",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "transform_test = gdata.vision.transforms.Compose([\n",
        "    gdata.vision.transforms.ToTensor(), \n",
        "    gdata.vision.transforms.Normalize([0.4914, 0.4822, 0.4465], [0.2023, 0.1194, 0.2010])\n",
        "])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r_NKYZbgkX2l",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_ds = gdata.vision.ImageFolderDataset(os.path.join(data_dir, input_dir, 'train'), flag=1)\n",
        "valid_ds = gdata.vision.ImageFolderDataset(os.path.join(data_dir, input_dir, 'valid'), flag=1)\n",
        "train_valid_ds = gdata.vision.ImageFolderDataset(os.path.join(data_dir, input_dir, 'train_valid'), flag=1)\n",
        "test_ds = gdata.vision.ImageFolderDataset(os.path.join(data_dir, input_dir, 'test'), flag=1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yet7WlU0rFln",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_iter = gdata.DataLoader(train_ds.transform_first(transform_train), batch_size, shuffle=True, last_batch='keep')\n",
        "valid_iter = gdata.DataLoader(valid_ds.transform_first(transform_test), batch_size, shuffle=True, last_batch='keep')\n",
        "train_valid_iter = gdata.DataLoader(train_valid_ds.transform_first(transform_train), batch_size, shuffle=True, last_batch='keep')\n",
        "test_iter = gdata.DataLoader(test_ds.transform_first(transform_test), batch_size, shuffle=False, last_batch='keep')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_bbNtbe0sgQy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Residual(nn.HybridBlock):\n",
        "    def __init__(self, num_channels, use_1x1conv=False, strides=1, **kwargs):\n",
        "        super(Residual, self).__init__(**kwargs)\n",
        "        self.conv1 = nn.Conv2D(num_channels, kernel_size=3, padding=1, strides=strides)\n",
        "        self.conv2 = nn.Conv2D(num_channels, kernel_size=3, padding=1)\n",
        "        if use_1x1conv:\n",
        "            self.conv3 = nn.Conv2D(num_channels, kernel_size=1, strides=strides)\n",
        "        else:\n",
        "            self.conv3 = None \n",
        "        self.bn1 = nn.BatchNorm()\n",
        "        self.bn2 = nn.BatchNorm()\n",
        "\n",
        "    def hybrid_forward(self, F, X):\n",
        "        Y = F.relu(self.bn1(self.conv1(X)))\n",
        "        Y = self.bn2(self.conv2(Y))\n",
        "        if self.conv3:\n",
        "            X = self.conv3(X) \n",
        "        return F.relu(Y + X)\n",
        "        print('13')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vKDjCL-WAoYh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def resnet18(num_classes):\n",
        "    net = nn.HybridSequential()\n",
        "    net.add(nn.Conv2D(64, kernel_size=3, strides=1, padding=1), \n",
        "        nn.BatchNorm(), nn.Activation('relu'))\n",
        "    \n",
        "    def resnet_block(num_channels, num_residuals, first_block=False):\n",
        "        blk = nn.HybridSequential()\n",
        "        for i in range(num_residuals):\n",
        "            if i == 0 and not first_block:\n",
        "                blk.add(Residual(num_channels, use_1x1conv=True, strides=2))\n",
        "            else:\n",
        "                blk.add(Residual(num_channels))\n",
        "        return blk \n",
        "\n",
        "    net.add(resnet_block(64, 2, first_block=True), \n",
        "        resnet_block(128, 2), \n",
        "        resnet_block(256, 2), \n",
        "        resnet_block(512, 2))\n",
        "    net.add(nn.GlobalAvgPool2D(), nn.Dense(num_classes))\n",
        "    return net \n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8VbSrXqmDIsQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_net(ctx):\n",
        "    num_classes = 10 \n",
        "    net = resnet18(num_classes)\n",
        "    net.initialize(ctx=ctx, init=init.Xavier())\n",
        "    return net \n",
        "\n",
        "loss = gloss.SoftmaxCrossEntropyLoss()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5hl8TouHDiAT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def train(net, train_iter, valid_iter, num_epochs, lr, wd, ctx, lr_period, lr_decay):\n",
        "    trainer = gluon.Trainer(net.collect_params(), 'sgd', {'learning_rate': lr, 'momentum':0.9, 'wd':wd})\n",
        "    for epoch in range(num_epochs):\n",
        "        train_l_sum, train_acc_sum, n, start = 0.0, 0.0, 0, time.time()\n",
        "        if epoch > 0 and epoch % lr_period == 0:\n",
        "            trainer.set_learning_rate(trainer.learning_rate * lr_decay)\n",
        "        for X, y in train_iter:\n",
        "            y = y.astype('float32').as_in_context(ctx)\n",
        "            with autograd.record():\n",
        "                y_hat = net(X.as_in_context(ctx))\n",
        "                l = loss(y_hat, y).sum()\n",
        "            l.backward()\n",
        "            trainer.step(batch_size)\n",
        "            train_l_sum += l.asscalar()\n",
        "            train_acc_sum += (y_hat.argmax(axis=1) == y).sum().asscalar()\n",
        "            n += y.size \n",
        "        time_s = 'time %.2f sec' % (time.time() - start)\n",
        "        if valid_iter is not None:\n",
        "            valid_acc = d2l.evaluate_accuracy(valid_iter, net, ctx)\n",
        "            epoch_s = (\"epoch %d, loss %f, train acc %f, valid acc %f, \"\n",
        "                % (epoch + 1, train_l_sum / n, train_acc_sum / n, valid_acc))\n",
        "        else:\n",
        "            epoch_s = ('epoch %d, loss %f, train acc %f, ' \n",
        "                % (epoch + 1, train_l_sum / n, train_acc_sum / n))\n",
        "            print(epoch_s + time_s + ', lr ' + str(trainer.learning_rate))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SOHXrxoeI_eC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "ctx, num_epochs, lr, wd = d2l.try_gpu(), 1, 0.1, 5e-4 \n",
        "lr_period, lr_decay, net = 80, 0.1, get_net(ctx)\n",
        "net.hybridize()\n",
        "train(net, train_iter, valid_iter, num_epochs, lr, wd, ctx, lr_period, lr_decay)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZWHX7BH-HOaH",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "25d1e5eb-7fd1-4f44-ab09-6d9cb878cbb5"
      },
      "source": [
        "net, preds = get_net(ctx), []\n",
        "net.hybridize()\n",
        "train(net, train_valid_iter, None, num_epochs, lr, wd, ctx, lr_period, lr_decay)\n",
        "\n",
        "for X, _ in test_iter:\n",
        "    y_hat = net(X.as_in_context(ctx))\n",
        "    preds.extend(y_hat.argmax(axis=1).astype(int).asnumpy())\n",
        "sorted_ids = list(range(1, len(test_ds) + 1))\n",
        "sorted_ids.sort(key=lambda x: str(x))\n",
        "df = pd.DataFrame({'id': sorted_ids, 'label': preds})\n",
        "df['label'] = df['label'].apply(lambda x: train_valid_ds.synsets[x])\n",
        "df.to_csv('submission.csv', index=False)"
      ],
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "epoch 1, loss nan, train acc 0.100000, time 20.31 sec, lr 0.1\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}