{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "1022.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/yananma/5_programs_per_day/blob/master/1022.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OXw2N97509K8",
        "colab_type": "text"
      },
      "source": [
        "## 1、Basics"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tJJesy3n1HVI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch \n",
        "import torch.nn as nn \n",
        "import torchvision \n",
        "import torchvision.transforms as transforms \n",
        "import numpy as np "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O3ZWUJiv1cc7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x = torch.tensor(1., requires_grad=True)\n",
        "w = torch.tensor(2., requires_grad=True)\n",
        "b = torch.tensor(3., requires_grad=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FpWnwLQS1vX1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "y = w * x + b"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2uB9QEIl1x5s",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "y.backward()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ej6Zj-Ri2KAd",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        },
        "outputId": "badf4765-3497-45ca-a10a-931056e1694c"
      },
      "source": [
        "print(x.grad)\n",
        "print(w.grad)\n",
        "print(b.grad)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor(2.)\n",
            "tensor(1.)\n",
            "tensor(1.)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EV_EhDAJ2PP1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x = torch.randn(10, 3)\n",
        "y = torch.randn(10, 2)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O-6rn8li2Xkl",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 193
        },
        "outputId": "2513e656-56af-4fc5-e6bd-ed6ebe7ef695"
      },
      "source": [
        "print(x)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[ 1.0312, -2.2192, -0.6348],\n",
            "        [-1.5189,  0.3702,  0.9602],\n",
            "        [ 0.1898,  0.3289, -0.0811],\n",
            "        [-2.5768,  0.7972, -0.9014],\n",
            "        [ 0.0455,  0.3736,  1.9475],\n",
            "        [ 0.7540,  0.8177, -1.4106],\n",
            "        [-0.3222,  1.7772, -0.5625],\n",
            "        [-0.5454,  0.1586, -0.7365],\n",
            "        [ 1.0256, -2.4679, -0.8952],\n",
            "        [ 0.8316,  0.5770, -0.3232]])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YAQbDlcV2Z09",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        },
        "outputId": "ac253016-d6fa-4465-8b9b-dfcebc5a172f"
      },
      "source": [
        "linear = nn.Linear(3, 2)\n",
        "print(linear.weight)"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Parameter containing:\n",
            "tensor([[-0.2948,  0.1837,  0.0578],\n",
            "        [ 0.3154, -0.4837,  0.1353]], requires_grad=True)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cj6E5aLTamib",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "8d3a87b9-7ac3-48a7-da70-592a55b00303"
      },
      "source": [
        "print(linear.weight.size())"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([2, 3])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mF2ebTFaawWa",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "7dd46af9-bf1a-4b9e-e960-f404e0023d40"
      },
      "source": [
        "print(linear.weight.size(1))"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "3\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iLvEvHiB6qGH",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "d6ebc2b2-98d2-481e-ef57-8553fddeec5d"
      },
      "source": [
        "print(linear.bias)"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Parameter containing:\n",
            "tensor([ 0.1048, -0.1609], requires_grad=True)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y_Q5hOVh60DF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "criterion = nn.MSELoss()\n",
        "optimizer = torch.optim.SGD(linear.parameters(), lr=0.01)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sxo2GtVU7D64",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "pred = linear(x)\n",
        "loss = criterion(pred, y)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qu1CU9Vr7MyW",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 318
        },
        "outputId": "17be8583-0dd3-4166-e720-7e84f491d9ad"
      },
      "source": [
        "!pip install mxnet"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting mxnet\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/92/6c/c6e5562f8face683cec73f5d4d74a58f8572c0595d54f1fed9d923020bbd/mxnet-1.5.1.post0-py2.py3-none-manylinux1_x86_64.whl (25.4MB)\n",
            "\u001b[K     |████████████████████████████████| 25.4MB 1.2MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy<2.0.0,>1.16.0 in /usr/local/lib/python3.6/dist-packages (from mxnet) (1.16.5)\n",
            "Requirement already satisfied: requests<3,>=2.20.0 in /usr/local/lib/python3.6/dist-packages (from mxnet) (2.21.0)\n",
            "Collecting graphviz<0.9.0,>=0.8.1 (from mxnet)\n",
            "  Downloading https://files.pythonhosted.org/packages/53/39/4ab213673844e0c004bed8a0781a0721a3f6bb23eb8854ee75c236428892/graphviz-0.8.4-py2.py3-none-any.whl\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.20.0->mxnet) (2019.9.11)\n",
            "Requirement already satisfied: urllib3<1.25,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.20.0->mxnet) (1.24.3)\n",
            "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.20.0->mxnet) (3.0.4)\n",
            "Requirement already satisfied: idna<2.9,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.20.0->mxnet) (2.8)\n",
            "Installing collected packages: graphviz, mxnet\n",
            "  Found existing installation: graphviz 0.10.1\n",
            "    Uninstalling graphviz-0.10.1:\n",
            "      Successfully uninstalled graphviz-0.10.1\n",
            "Successfully installed graphviz-0.8.4 mxnet-1.5.1.post0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fRRoSUAAkPhg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from mxnet import nd "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nqd0ReTUkdD4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x = nd.arange(12)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zsk6SXqqkhGI",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        },
        "outputId": "f2f1bcab-42b1-4bc5-dbd2-b1d78877fb74"
      },
      "source": [
        "x"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\n",
              "[ 0.  1.  2.  3.  4.  5.  6.  7.  8.  9. 10. 11.]\n",
              "<NDArray 12 @cpu(0)>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nbG9OhFJki2g",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "67c29584-09f5-421f-cacb-11225dd380e6"
      },
      "source": [
        "x.shape"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(12,)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WWMRki2Gko7h",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "e33b20bf-554e-4b84-af5f-b05567a5771b"
      },
      "source": [
        "x.size"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "12"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Tbeb637yksU6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X = x.reshape((3, 4))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3rM_e67gkxtz",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 105
        },
        "outputId": "11a6dd43-3c94-4472-d603-2f961eafd51b"
      },
      "source": [
        "X"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\n",
              "[[ 0.  1.  2.  3.]\n",
              " [ 4.  5.  6.  7.]\n",
              " [ 8.  9. 10. 11.]]\n",
              "<NDArray 3x4 @cpu(0)>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JAx_Ys0Sk2la",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 175
        },
        "outputId": "021bce58-2fad-4264-b3d2-3c73c72e6d93"
      },
      "source": [
        "nd.zeros((2, 3, 4))"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\n",
              "[[[0. 0. 0. 0.]\n",
              "  [0. 0. 0. 0.]\n",
              "  [0. 0. 0. 0.]]\n",
              "\n",
              " [[0. 0. 0. 0.]\n",
              "  [0. 0. 0. 0.]\n",
              "  [0. 0. 0. 0.]]]\n",
              "<NDArray 2x3x4 @cpu(0)>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t0QlGupVk80C",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 105
        },
        "outputId": "2ff3c8d1-ec90-4d0e-9915-8f0c5425b7d0"
      },
      "source": [
        "nd.ones((3, 4))"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\n",
              "[[1. 1. 1. 1.]\n",
              " [1. 1. 1. 1.]\n",
              " [1. 1. 1. 1.]]\n",
              "<NDArray 3x4 @cpu(0)>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wwb4g81HlDIU",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 105
        },
        "outputId": "37480549-c219-4c5e-cbb4-c3a1b41bedba"
      },
      "source": [
        "Y = nd.array([[2, 1, 4, 3], [1, 2, 3, 4], [4, 3, 2, 1]])\n",
        "Y"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\n",
              "[[2. 1. 4. 3.]\n",
              " [1. 2. 3. 4.]\n",
              " [4. 3. 2. 1.]]\n",
              "<NDArray 3x4 @cpu(0)>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "atdyP_u2lNlB",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 105
        },
        "outputId": "4035a0f2-4ad3-4832-97e1-65263b06c50d"
      },
      "source": [
        "nd.random.normal(10, 1, shape=(3, 4))"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\n",
              "[[10.244422  9.962839  9.51225   9.977383]\n",
              " [10.574615 11.466126 10.686291 10.354961]\n",
              " [11.07317  10.120174  9.02889   9.224303]]\n",
              "<NDArray 3x4 @cpu(0)>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CW-D1qfKlXNx",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 105
        },
        "outputId": "a3b1a981-7266-4cee-fe74-7bf6f8df2e80"
      },
      "source": [
        "X + Y"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\n",
              "[[ 2.  2.  6.  6.]\n",
              " [ 5.  7.  9. 11.]\n",
              " [12. 12. 12. 12.]]\n",
              "<NDArray 3x4 @cpu(0)>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7ZcPtIvdlgbZ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 105
        },
        "outputId": "650c61ab-107d-4774-f7ae-f26e360db5a4"
      },
      "source": [
        "X * Y"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\n",
              "[[ 0.  1.  8.  9.]\n",
              " [ 4. 10. 18. 28.]\n",
              " [32. 27. 20. 11.]]\n",
              "<NDArray 3x4 @cpu(0)>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2_5zOgpOln4S",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 105
        },
        "outputId": "ba1b5b53-dfe8-446f-dad4-7cefe2c90675"
      },
      "source": [
        "X / Y"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\n",
              "[[ 0.    1.    0.5   1.  ]\n",
              " [ 4.    2.5   2.    1.75]\n",
              " [ 2.    3.    5.   11.  ]]\n",
              "<NDArray 3x4 @cpu(0)>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5WhU6ZuRlunp",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 105
        },
        "outputId": "252bebee-e20e-4835-9a34-c0070a77fa71"
      },
      "source": [
        "Y.exp()"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\n",
              "[[ 7.389056   2.7182817 54.59815   20.085537 ]\n",
              " [ 2.7182817  7.389056  20.085537  54.59815  ]\n",
              " [54.59815   20.085537   7.389056   2.7182817]]\n",
              "<NDArray 3x4 @cpu(0)>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "997t96OBlxFy",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 105
        },
        "outputId": "6c6e7557-9c43-46d1-ac7c-92a60657fcf1"
      },
      "source": [
        "nd.dot(X, Y.T)"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\n",
              "[[ 18.  20.  10.]\n",
              " [ 58.  60.  50.]\n",
              " [ 98. 100.  90.]]\n",
              "<NDArray 3x3 @cpu(0)>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I9HO1kvOl68D",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 157
        },
        "outputId": "65ccfee2-fcf7-4563-c012-cd5f8f7bf170"
      },
      "source": [
        "nd.concat(X, Y, dim=0)"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\n",
              "[[ 0.  1.  2.  3.]\n",
              " [ 4.  5.  6.  7.]\n",
              " [ 8.  9. 10. 11.]\n",
              " [ 2.  1.  4.  3.]\n",
              " [ 1.  2.  3.  4.]\n",
              " [ 4.  3.  2.  1.]]\n",
              "<NDArray 6x4 @cpu(0)>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wbU0OIRJmPKS",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 105
        },
        "outputId": "4f319fa1-b06b-4994-ff8d-91a433938403"
      },
      "source": [
        "nd.concat(X, Y, dim=1)"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\n",
              "[[ 0.  1.  2.  3.  2.  1.  4.  3.]\n",
              " [ 4.  5.  6.  7.  1.  2.  3.  4.]\n",
              " [ 8.  9. 10. 11.  4.  3.  2.  1.]]\n",
              "<NDArray 3x8 @cpu(0)>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AboUBNmjmVyE",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 105
        },
        "outputId": "1d896472-8dd6-4eff-aefd-78d08525e729"
      },
      "source": [
        "X == Y"
      ],
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\n",
              "[[0. 1. 0. 1.]\n",
              " [0. 0. 0. 0.]\n",
              " [0. 0. 0. 0.]]\n",
              "<NDArray 3x4 @cpu(0)>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LGKSN-kpmbDq",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        },
        "outputId": "4bbf2b0e-78f7-4a64-e7c5-82722431551e"
      },
      "source": [
        "X.sum()"
      ],
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\n",
              "[66.]\n",
              "<NDArray 1 @cpu(0)>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ws8JM--Xmds6",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "94c51f76-878f-44e8-b6a9-426696a66120"
      },
      "source": [
        "X.norm().asscalar()"
      ],
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "22.494442"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 46
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M5ufewiamniT",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 140
        },
        "outputId": "9d2b5d7b-7b9e-4f05-e4ef-52641ac5924d"
      },
      "source": [
        "A = nd.arange(3).reshape((3, 1))\n",
        "B = nd.arange(2).reshape((1, 2))\n",
        "A, B"
      ],
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(\n",
              " [[0.]\n",
              "  [1.]\n",
              "  [2.]]\n",
              " <NDArray 3x1 @cpu(0)>, \n",
              " [[0. 1.]]\n",
              " <NDArray 1x2 @cpu(0)>)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 47
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V8m_z3eZ5hMw",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 105
        },
        "outputId": "ae578249-352c-4109-88db-91542ea28d99"
      },
      "source": [
        "A + B"
      ],
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\n",
              "[[0. 1.]\n",
              " [1. 2.]\n",
              " [2. 3.]]\n",
              "<NDArray 3x2 @cpu(0)>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 48
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "awm_3eRd5rkm",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 105
        },
        "outputId": "e976097d-c760-4b80-a031-fe21970499fe"
      },
      "source": [
        "X"
      ],
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\n",
              "[[ 0.  1.  2.  3.]\n",
              " [ 4.  5.  6.  7.]\n",
              " [ 8.  9. 10. 11.]]\n",
              "<NDArray 3x4 @cpu(0)>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 51
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7lV1GGsa55Kn",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 87
        },
        "outputId": "a6512504-b90c-4a4d-ad61-4e0b412dd3c8"
      },
      "source": [
        "X[1:3]"
      ],
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\n",
              "[[ 4.  5.  6.  7.]\n",
              " [ 8.  9. 10. 11.]]\n",
              "<NDArray 2x4 @cpu(0)>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 52
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_GYHgvde6ALn",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 105
        },
        "outputId": "d93fb0bc-8f81-47eb-c6bb-e7cb580a5552"
      },
      "source": [
        "X[1, 2] = 9\n",
        "X"
      ],
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\n",
              "[[ 0.  1.  2.  3.]\n",
              " [ 4.  5.  9.  7.]\n",
              " [ 8.  9. 10. 11.]]\n",
              "<NDArray 3x4 @cpu(0)>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 53
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mjKR3hG26frw",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 105
        },
        "outputId": "7ef4cd78-8582-4c28-ce4b-da3f039cd46b"
      },
      "source": [
        "X[1:2, :] = 12 \n",
        "X"
      ],
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\n",
              "[[ 0.  1.  2.  3.]\n",
              " [12. 12. 12. 12.]\n",
              " [ 8.  9. 10. 11.]]\n",
              "<NDArray 3x4 @cpu(0)>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 55
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WfILBqR26qcx",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "3db12f5b-0aab-4d82-fb47-3505e59407ee"
      },
      "source": [
        "before = id(Y)\n",
        "Y = Y + X\n",
        "id(Y) == before"
      ],
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "False"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 56
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0ycx_yCs6-KG",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "5589bd5d-3deb-4feb-96e0-48fd40ab0849"
      },
      "source": [
        "Z = Y.zeros_like()\n",
        "before = id(Z)\n",
        "Z[:] = X + Y \n",
        "id(Z) == before"
      ],
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 61
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W5cDB4wL7Wdf",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "9447a158-8596-4109-a67a-a431e5f84f7b"
      },
      "source": [
        "nd.elemwise_add(X, Y, out=Z)\n",
        "id(Z) == before"
      ],
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 62
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WKhP4SGd8CSd",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "b2f3e87f-9180-4a7a-f48f-ae931b26a86f"
      },
      "source": [
        "before = id(X)\n",
        "X += Y \n",
        "id(X) == before"
      ],
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 63
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JOhLv3OV8PMY",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 87
        },
        "outputId": "de05e547-5475-4c02-d4b1-3585d16d0807"
      },
      "source": [
        "import numpy as np \n",
        "\n",
        "P = np.ones((2, 3))\n",
        "D = nd.array(P)\n",
        "D"
      ],
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\n",
              "[[1. 1. 1.]\n",
              " [1. 1. 1.]]\n",
              "<NDArray 2x3 @cpu(0)>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 64
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zM1J6Vgg8ceJ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "39d8165e-405a-472f-822d-7e0e0f62cf4a"
      },
      "source": [
        "D.asnumpy()"
      ],
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[1., 1., 1.],\n",
              "       [1., 1., 1.]], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 65
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nNaNpf529Q7Y",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from mxnet import autograd, nd"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J6QCvlDJ9eIS",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        },
        "outputId": "30a5b0f3-07b4-4ffb-8d05-f0460df67333"
      },
      "source": [
        "x = nd.arange(4).reshape((4, 1))\n",
        "x"
      ],
      "execution_count": 68,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\n",
              "[[0.]\n",
              " [1.]\n",
              " [2.]\n",
              " [3.]]\n",
              "<NDArray 4x1 @cpu(0)>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 68
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J65Z1bpm9qoj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x.attach_grad()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z6yJ-ow2RF5W",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "with autograd.record():\n",
        "    y = 2 * nd.dot(x.T, x)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y4SJIetIRPnv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "y.backward()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3RBwOb9fRbWf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "y.grad"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NJvnHbQKRpZ-",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        },
        "outputId": "19b656e9-07b1-4e2e-cf09-28e178e6e66e"
      },
      "source": [
        "x.grad"
      ],
      "execution_count": 74,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\n",
              "[[ 0.]\n",
              " [ 4.]\n",
              " [ 8.]\n",
              " [12.]]\n",
              "<NDArray 4x1 @cpu(0)>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 74
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-w6DHQwnRxg_",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        },
        "outputId": "3cc14e99-12c2-4381-b190-83118216200a"
      },
      "source": [
        "assert (x.grad - 4 * x).norm().asscalar() == 0\n",
        "x.grad"
      ],
      "execution_count": 75,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\n",
              "[[ 0.]\n",
              " [ 4.]\n",
              " [ 8.]\n",
              " [12.]]\n",
              "<NDArray 4x1 @cpu(0)>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 75
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XFu7oJ3QR_u9",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "52be6fd1-81bb-46f3-c7d5-576863ca16f4"
      },
      "source": [
        "print(autograd.is_training())\n",
        "with autograd.record():\n",
        "    print(autograd.is_training())"
      ],
      "execution_count": 76,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "False\n",
            "True\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IVGh_r5OSXNv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def f(a):\n",
        "    b = a * 2 \n",
        "    while b.norm().asscalar() < 1000:\n",
        "        b = b * 2 \n",
        "    if b.sum().asscalar() > 0:\n",
        "        c = b \n",
        "    else:\n",
        "        c = 100 * b \n",
        "    return c "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3eXk9bH1TBfU",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "f32aff4f-cfe6-416a-afe2-41eb873b3329"
      },
      "source": [
        "help(nn.Linear)"
      ],
      "execution_count": 79,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Help on class Linear in module torch.nn.modules.linear:\n",
            "\n",
            "class Linear(torch.nn.modules.module.Module)\n",
            " |  Applies a linear transformation to the incoming data: :math:`y = xA^T + b`\n",
            " |  \n",
            " |  Args:\n",
            " |      in_features: size of each input sample\n",
            " |      out_features: size of each output sample\n",
            " |      bias: If set to ``False``, the layer will not learn an additive bias.\n",
            " |          Default: ``True``\n",
            " |  \n",
            " |  Shape:\n",
            " |      - Input: :math:`(N, *, H_{in})` where :math:`*` means any number of\n",
            " |        additional dimensions and :math:`H_{in} = \\text{in\\_features}`\n",
            " |      - Output: :math:`(N, *, H_{out})` where all but the last dimension\n",
            " |        are the same shape as the input and :math:`H_{out} = \\text{out\\_features}`.\n",
            " |  \n",
            " |  Attributes:\n",
            " |      weight: the learnable weights of the module of shape\n",
            " |          :math:`(\\text{out\\_features}, \\text{in\\_features})`. The values are\n",
            " |          initialized from :math:`\\mathcal{U}(-\\sqrt{k}, \\sqrt{k})`, where\n",
            " |          :math:`k = \\frac{1}{\\text{in\\_features}}`\n",
            " |      bias:   the learnable bias of the module of shape :math:`(\\text{out\\_features})`.\n",
            " |              If :attr:`bias` is ``True``, the values are initialized from\n",
            " |              :math:`\\mathcal{U}(-\\sqrt{k}, \\sqrt{k})` where\n",
            " |              :math:`k = \\frac{1}{\\text{in\\_features}}`\n",
            " |  \n",
            " |  Examples::\n",
            " |  \n",
            " |      >>> m = nn.Linear(20, 30)\n",
            " |      >>> input = torch.randn(128, 20)\n",
            " |      >>> output = m(input)\n",
            " |      >>> print(output.size())\n",
            " |      torch.Size([128, 30])\n",
            " |  \n",
            " |  Method resolution order:\n",
            " |      Linear\n",
            " |      torch.nn.modules.module.Module\n",
            " |      builtins.object\n",
            " |  \n",
            " |  Methods defined here:\n",
            " |  \n",
            " |  __init__(self, in_features, out_features, bias=True)\n",
            " |      Initializes internal Module state, shared by both nn.Module and ScriptModule.\n",
            " |  \n",
            " |  extra_repr(self)\n",
            " |      Set the extra representation of the module\n",
            " |      \n",
            " |      To print customized extra information, you should reimplement\n",
            " |      this method in your own modules. Both single-line and multi-line\n",
            " |      strings are acceptable.\n",
            " |  \n",
            " |  forward(self, input)\n",
            " |      Defines the computation performed at every call.\n",
            " |      \n",
            " |      Should be overridden by all subclasses.\n",
            " |      \n",
            " |      .. note::\n",
            " |          Although the recipe for forward pass needs to be defined within\n",
            " |          this function, one should call the :class:`Module` instance afterwards\n",
            " |          instead of this since the former takes care of running the\n",
            " |          registered hooks while the latter silently ignores them.\n",
            " |  \n",
            " |  reset_parameters(self)\n",
            " |  \n",
            " |  ----------------------------------------------------------------------\n",
            " |  Data and other attributes defined here:\n",
            " |  \n",
            " |  __constants__ = ['bias', 'in_features', 'out_features']\n",
            " |  \n",
            " |  ----------------------------------------------------------------------\n",
            " |  Methods inherited from torch.nn.modules.module.Module:\n",
            " |  \n",
            " |  __call__(self, *input, **kwargs)\n",
            " |      Call self as a function.\n",
            " |  \n",
            " |  __delattr__(self, name)\n",
            " |      Implement delattr(self, name).\n",
            " |  \n",
            " |  __dir__(self)\n",
            " |      __dir__() -> list\n",
            " |      default dir() implementation\n",
            " |  \n",
            " |  __getattr__(self, name)\n",
            " |  \n",
            " |  __repr__(self)\n",
            " |      Return repr(self).\n",
            " |  \n",
            " |  __setattr__(self, name, value)\n",
            " |      Implement setattr(self, name, value).\n",
            " |  \n",
            " |  __setstate__(self, state)\n",
            " |  \n",
            " |  add_module(self, name, module)\n",
            " |      Adds a child module to the current module.\n",
            " |      \n",
            " |      The module can be accessed as an attribute using the given name.\n",
            " |      \n",
            " |      Args:\n",
            " |          name (string): name of the child module. The child module can be\n",
            " |              accessed from this module using the given name\n",
            " |          module (Module): child module to be added to the module.\n",
            " |  \n",
            " |  apply(self, fn)\n",
            " |      Applies ``fn`` recursively to every submodule (as returned by ``.children()``)\n",
            " |      as well as self. Typical use includes initializing the parameters of a model\n",
            " |      (see also :ref:`torch-nn-init`).\n",
            " |      \n",
            " |      Args:\n",
            " |          fn (:class:`Module` -> None): function to be applied to each submodule\n",
            " |      \n",
            " |      Returns:\n",
            " |          Module: self\n",
            " |      \n",
            " |      Example::\n",
            " |      \n",
            " |          >>> def init_weights(m):\n",
            " |          >>>     print(m)\n",
            " |          >>>     if type(m) == nn.Linear:\n",
            " |          >>>         m.weight.data.fill_(1.0)\n",
            " |          >>>         print(m.weight)\n",
            " |          >>> net = nn.Sequential(nn.Linear(2, 2), nn.Linear(2, 2))\n",
            " |          >>> net.apply(init_weights)\n",
            " |          Linear(in_features=2, out_features=2, bias=True)\n",
            " |          Parameter containing:\n",
            " |          tensor([[ 1.,  1.],\n",
            " |                  [ 1.,  1.]])\n",
            " |          Linear(in_features=2, out_features=2, bias=True)\n",
            " |          Parameter containing:\n",
            " |          tensor([[ 1.,  1.],\n",
            " |                  [ 1.,  1.]])\n",
            " |          Sequential(\n",
            " |            (0): Linear(in_features=2, out_features=2, bias=True)\n",
            " |            (1): Linear(in_features=2, out_features=2, bias=True)\n",
            " |          )\n",
            " |          Sequential(\n",
            " |            (0): Linear(in_features=2, out_features=2, bias=True)\n",
            " |            (1): Linear(in_features=2, out_features=2, bias=True)\n",
            " |          )\n",
            " |  \n",
            " |  buffers(self, recurse=True)\n",
            " |      Returns an iterator over module buffers.\n",
            " |      \n",
            " |      Args:\n",
            " |          recurse (bool): if True, then yields buffers of this module\n",
            " |              and all submodules. Otherwise, yields only buffers that\n",
            " |              are direct members of this module.\n",
            " |      \n",
            " |      Yields:\n",
            " |          torch.Tensor: module buffer\n",
            " |      \n",
            " |      Example::\n",
            " |      \n",
            " |          >>> for buf in model.buffers():\n",
            " |          >>>     print(type(buf.data), buf.size())\n",
            " |          <class 'torch.FloatTensor'> (20L,)\n",
            " |          <class 'torch.FloatTensor'> (20L, 1L, 5L, 5L)\n",
            " |  \n",
            " |  children(self)\n",
            " |      Returns an iterator over immediate children modules.\n",
            " |      \n",
            " |      Yields:\n",
            " |          Module: a child module\n",
            " |  \n",
            " |  cpu(self)\n",
            " |      Moves all model parameters and buffers to the CPU.\n",
            " |      \n",
            " |      Returns:\n",
            " |          Module: self\n",
            " |  \n",
            " |  cuda(self, device=None)\n",
            " |      Moves all model parameters and buffers to the GPU.\n",
            " |      \n",
            " |      This also makes associated parameters and buffers different objects. So\n",
            " |      it should be called before constructing optimizer if the module will\n",
            " |      live on GPU while being optimized.\n",
            " |      \n",
            " |      Arguments:\n",
            " |          device (int, optional): if specified, all parameters will be\n",
            " |              copied to that device\n",
            " |      \n",
            " |      Returns:\n",
            " |          Module: self\n",
            " |  \n",
            " |  double(self)\n",
            " |      Casts all floating point parameters and buffers to ``double`` datatype.\n",
            " |      \n",
            " |      Returns:\n",
            " |          Module: self\n",
            " |  \n",
            " |  eval(self)\n",
            " |      Sets the module in evaluation mode.\n",
            " |      \n",
            " |      This has any effect only on certain modules. See documentations of\n",
            " |      particular modules for details of their behaviors in training/evaluation\n",
            " |      mode, if they are affected, e.g. :class:`Dropout`, :class:`BatchNorm`,\n",
            " |      etc.\n",
            " |      \n",
            " |      This is equivalent with :meth:`self.train(False) <torch.nn.Module.train>`.\n",
            " |      \n",
            " |      Returns:\n",
            " |          Module: self\n",
            " |  \n",
            " |  float(self)\n",
            " |      Casts all floating point parameters and buffers to float datatype.\n",
            " |      \n",
            " |      Returns:\n",
            " |          Module: self\n",
            " |  \n",
            " |  half(self)\n",
            " |      Casts all floating point parameters and buffers to ``half`` datatype.\n",
            " |      \n",
            " |      Returns:\n",
            " |          Module: self\n",
            " |  \n",
            " |  load_state_dict(self, state_dict, strict=True)\n",
            " |      Copies parameters and buffers from :attr:`state_dict` into\n",
            " |      this module and its descendants. If :attr:`strict` is ``True``, then\n",
            " |      the keys of :attr:`state_dict` must exactly match the keys returned\n",
            " |      by this module's :meth:`~torch.nn.Module.state_dict` function.\n",
            " |      \n",
            " |      Arguments:\n",
            " |          state_dict (dict): a dict containing parameters and\n",
            " |              persistent buffers.\n",
            " |          strict (bool, optional): whether to strictly enforce that the keys\n",
            " |              in :attr:`state_dict` match the keys returned by this module's\n",
            " |              :meth:`~torch.nn.Module.state_dict` function. Default: ``True``\n",
            " |      \n",
            " |      Returns:\n",
            " |          ``NamedTuple`` with ``missing_keys`` and ``unexpected_keys`` fields:\n",
            " |              * **missing_keys** is a list of str containing the missing keys\n",
            " |              * **unexpected_keys** is a list of str containing the unexpected keys\n",
            " |  \n",
            " |  modules(self)\n",
            " |      Returns an iterator over all modules in the network.\n",
            " |      \n",
            " |      Yields:\n",
            " |          Module: a module in the network\n",
            " |      \n",
            " |      Note:\n",
            " |          Duplicate modules are returned only once. In the following\n",
            " |          example, ``l`` will be returned only once.\n",
            " |      \n",
            " |      Example::\n",
            " |      \n",
            " |          >>> l = nn.Linear(2, 2)\n",
            " |          >>> net = nn.Sequential(l, l)\n",
            " |          >>> for idx, m in enumerate(net.modules()):\n",
            " |                  print(idx, '->', m)\n",
            " |      \n",
            " |          0 -> Sequential(\n",
            " |            (0): Linear(in_features=2, out_features=2, bias=True)\n",
            " |            (1): Linear(in_features=2, out_features=2, bias=True)\n",
            " |          )\n",
            " |          1 -> Linear(in_features=2, out_features=2, bias=True)\n",
            " |  \n",
            " |  named_buffers(self, prefix='', recurse=True)\n",
            " |      Returns an iterator over module buffers, yielding both the\n",
            " |      name of the buffer as well as the buffer itself.\n",
            " |      \n",
            " |      Args:\n",
            " |          prefix (str): prefix to prepend to all buffer names.\n",
            " |          recurse (bool): if True, then yields buffers of this module\n",
            " |              and all submodules. Otherwise, yields only buffers that\n",
            " |              are direct members of this module.\n",
            " |      \n",
            " |      Yields:\n",
            " |          (string, torch.Tensor): Tuple containing the name and buffer\n",
            " |      \n",
            " |      Example::\n",
            " |      \n",
            " |          >>> for name, buf in self.named_buffers():\n",
            " |          >>>    if name in ['running_var']:\n",
            " |          >>>        print(buf.size())\n",
            " |  \n",
            " |  named_children(self)\n",
            " |      Returns an iterator over immediate children modules, yielding both\n",
            " |      the name of the module as well as the module itself.\n",
            " |      \n",
            " |      Yields:\n",
            " |          (string, Module): Tuple containing a name and child module\n",
            " |      \n",
            " |      Example::\n",
            " |      \n",
            " |          >>> for name, module in model.named_children():\n",
            " |          >>>     if name in ['conv4', 'conv5']:\n",
            " |          >>>         print(module)\n",
            " |  \n",
            " |  named_modules(self, memo=None, prefix='')\n",
            " |      Returns an iterator over all modules in the network, yielding\n",
            " |      both the name of the module as well as the module itself.\n",
            " |      \n",
            " |      Yields:\n",
            " |          (string, Module): Tuple of name and module\n",
            " |      \n",
            " |      Note:\n",
            " |          Duplicate modules are returned only once. In the following\n",
            " |          example, ``l`` will be returned only once.\n",
            " |      \n",
            " |      Example::\n",
            " |      \n",
            " |          >>> l = nn.Linear(2, 2)\n",
            " |          >>> net = nn.Sequential(l, l)\n",
            " |          >>> for idx, m in enumerate(net.named_modules()):\n",
            " |                  print(idx, '->', m)\n",
            " |      \n",
            " |          0 -> ('', Sequential(\n",
            " |            (0): Linear(in_features=2, out_features=2, bias=True)\n",
            " |            (1): Linear(in_features=2, out_features=2, bias=True)\n",
            " |          ))\n",
            " |          1 -> ('0', Linear(in_features=2, out_features=2, bias=True))\n",
            " |  \n",
            " |  named_parameters(self, prefix='', recurse=True)\n",
            " |      Returns an iterator over module parameters, yielding both the\n",
            " |      name of the parameter as well as the parameter itself.\n",
            " |      \n",
            " |      Args:\n",
            " |          prefix (str): prefix to prepend to all parameter names.\n",
            " |          recurse (bool): if True, then yields parameters of this module\n",
            " |              and all submodules. Otherwise, yields only parameters that\n",
            " |              are direct members of this module.\n",
            " |      \n",
            " |      Yields:\n",
            " |          (string, Parameter): Tuple containing the name and parameter\n",
            " |      \n",
            " |      Example::\n",
            " |      \n",
            " |          >>> for name, param in self.named_parameters():\n",
            " |          >>>    if name in ['bias']:\n",
            " |          >>>        print(param.size())\n",
            " |  \n",
            " |  parameters(self, recurse=True)\n",
            " |      Returns an iterator over module parameters.\n",
            " |      \n",
            " |      This is typically passed to an optimizer.\n",
            " |      \n",
            " |      Args:\n",
            " |          recurse (bool): if True, then yields parameters of this module\n",
            " |              and all submodules. Otherwise, yields only parameters that\n",
            " |              are direct members of this module.\n",
            " |      \n",
            " |      Yields:\n",
            " |          Parameter: module parameter\n",
            " |      \n",
            " |      Example::\n",
            " |      \n",
            " |          >>> for param in model.parameters():\n",
            " |          >>>     print(type(param.data), param.size())\n",
            " |          <class 'torch.FloatTensor'> (20L,)\n",
            " |          <class 'torch.FloatTensor'> (20L, 1L, 5L, 5L)\n",
            " |  \n",
            " |  register_backward_hook(self, hook)\n",
            " |      Registers a backward hook on the module.\n",
            " |      \n",
            " |      The hook will be called every time the gradients with respect to module\n",
            " |      inputs are computed. The hook should have the following signature::\n",
            " |      \n",
            " |          hook(module, grad_input, grad_output) -> Tensor or None\n",
            " |      \n",
            " |      The :attr:`grad_input` and :attr:`grad_output` may be tuples if the\n",
            " |      module has multiple inputs or outputs. The hook should not modify its\n",
            " |      arguments, but it can optionally return a new gradient with respect to\n",
            " |      input that will be used in place of :attr:`grad_input` in subsequent\n",
            " |      computations.\n",
            " |      \n",
            " |      Returns:\n",
            " |          :class:`torch.utils.hooks.RemovableHandle`:\n",
            " |              a handle that can be used to remove the added hook by calling\n",
            " |              ``handle.remove()``\n",
            " |      \n",
            " |      .. warning ::\n",
            " |      \n",
            " |          The current implementation will not have the presented behavior\n",
            " |          for complex :class:`Module` that perform many operations.\n",
            " |          In some failure cases, :attr:`grad_input` and :attr:`grad_output` will only\n",
            " |          contain the gradients for a subset of the inputs and outputs.\n",
            " |          For such :class:`Module`, you should use :func:`torch.Tensor.register_hook`\n",
            " |          directly on a specific input or output to get the required gradients.\n",
            " |  \n",
            " |  register_buffer(self, name, tensor)\n",
            " |      Adds a persistent buffer to the module.\n",
            " |      \n",
            " |      This is typically used to register a buffer that should not to be\n",
            " |      considered a model parameter. For example, BatchNorm's ``running_mean``\n",
            " |      is not a parameter, but is part of the persistent state.\n",
            " |      \n",
            " |      Buffers can be accessed as attributes using given names.\n",
            " |      \n",
            " |      Args:\n",
            " |          name (string): name of the buffer. The buffer can be accessed\n",
            " |              from this module using the given name\n",
            " |          tensor (Tensor): buffer to be registered.\n",
            " |      \n",
            " |      Example::\n",
            " |      \n",
            " |          >>> self.register_buffer('running_mean', torch.zeros(num_features))\n",
            " |  \n",
            " |  register_forward_hook(self, hook)\n",
            " |      Registers a forward hook on the module.\n",
            " |      \n",
            " |      The hook will be called every time after :func:`forward` has computed an output.\n",
            " |      It should have the following signature::\n",
            " |      \n",
            " |          hook(module, input, output) -> None or modified output\n",
            " |      \n",
            " |      The hook can modify the output. It can modify the input inplace but\n",
            " |      it will not have effect on forward since this is called after\n",
            " |      :func:`forward` is called.\n",
            " |      \n",
            " |      Returns:\n",
            " |          :class:`torch.utils.hooks.RemovableHandle`:\n",
            " |              a handle that can be used to remove the added hook by calling\n",
            " |              ``handle.remove()``\n",
            " |  \n",
            " |  register_forward_pre_hook(self, hook)\n",
            " |      Registers a forward pre-hook on the module.\n",
            " |      \n",
            " |      The hook will be called every time before :func:`forward` is invoked.\n",
            " |      It should have the following signature::\n",
            " |      \n",
            " |          hook(module, input) -> None or modified input\n",
            " |      \n",
            " |      The hook can modify the input. User can either return a tuple or a\n",
            " |      single modified value in the hook. We will wrap the value into a tuple\n",
            " |      if a single value is returned(unless that value is already a tuple).\n",
            " |      \n",
            " |      Returns:\n",
            " |          :class:`torch.utils.hooks.RemovableHandle`:\n",
            " |              a handle that can be used to remove the added hook by calling\n",
            " |              ``handle.remove()``\n",
            " |  \n",
            " |  register_parameter(self, name, param)\n",
            " |      Adds a parameter to the module.\n",
            " |      \n",
            " |      The parameter can be accessed as an attribute using given name.\n",
            " |      \n",
            " |      Args:\n",
            " |          name (string): name of the parameter. The parameter can be accessed\n",
            " |              from this module using the given name\n",
            " |          param (Parameter): parameter to be added to the module.\n",
            " |  \n",
            " |  requires_grad_(self, requires_grad=True)\n",
            " |      Change if autograd should record operations on parameters in this\n",
            " |      module.\n",
            " |      \n",
            " |      This method sets the parameters' :attr:`requires_grad` attributes\n",
            " |      in-place.\n",
            " |      \n",
            " |      This method is helpful for freezing part of the module for finetuning\n",
            " |      or training parts of a model individually (e.g., GAN training).\n",
            " |      \n",
            " |      Args:\n",
            " |          requires_grad (bool): whether autograd should record operations on\n",
            " |                                parameters in this module. Default: ``True``.\n",
            " |      \n",
            " |      Returns:\n",
            " |          Module: self\n",
            " |  \n",
            " |  share_memory(self)\n",
            " |  \n",
            " |  state_dict(self, destination=None, prefix='', keep_vars=False)\n",
            " |      Returns a dictionary containing a whole state of the module.\n",
            " |      \n",
            " |      Both parameters and persistent buffers (e.g. running averages) are\n",
            " |      included. Keys are corresponding parameter and buffer names.\n",
            " |      \n",
            " |      Returns:\n",
            " |          dict:\n",
            " |              a dictionary containing a whole state of the module\n",
            " |      \n",
            " |      Example::\n",
            " |      \n",
            " |          >>> module.state_dict().keys()\n",
            " |          ['bias', 'weight']\n",
            " |  \n",
            " |  to(self, *args, **kwargs)\n",
            " |      Moves and/or casts the parameters and buffers.\n",
            " |      \n",
            " |      This can be called as\n",
            " |      \n",
            " |      .. function:: to(device=None, dtype=None, non_blocking=False)\n",
            " |      \n",
            " |      .. function:: to(dtype, non_blocking=False)\n",
            " |      \n",
            " |      .. function:: to(tensor, non_blocking=False)\n",
            " |      \n",
            " |      Its signature is similar to :meth:`torch.Tensor.to`, but only accepts\n",
            " |      floating point desired :attr:`dtype` s. In addition, this method will\n",
            " |      only cast the floating point parameters and buffers to :attr:`dtype`\n",
            " |      (if given). The integral parameters and buffers will be moved\n",
            " |      :attr:`device`, if that is given, but with dtypes unchanged. When\n",
            " |      :attr:`non_blocking` is set, it tries to convert/move asynchronously\n",
            " |      with respect to the host if possible, e.g., moving CPU Tensors with\n",
            " |      pinned memory to CUDA devices.\n",
            " |      \n",
            " |      See below for examples.\n",
            " |      \n",
            " |      .. note::\n",
            " |          This method modifies the module in-place.\n",
            " |      \n",
            " |      Args:\n",
            " |          device (:class:`torch.device`): the desired device of the parameters\n",
            " |              and buffers in this module\n",
            " |          dtype (:class:`torch.dtype`): the desired floating point type of\n",
            " |              the floating point parameters and buffers in this module\n",
            " |          tensor (torch.Tensor): Tensor whose dtype and device are the desired\n",
            " |              dtype and device for all parameters and buffers in this module\n",
            " |      \n",
            " |      Returns:\n",
            " |          Module: self\n",
            " |      \n",
            " |      Example::\n",
            " |      \n",
            " |          >>> linear = nn.Linear(2, 2)\n",
            " |          >>> linear.weight\n",
            " |          Parameter containing:\n",
            " |          tensor([[ 0.1913, -0.3420],\n",
            " |                  [-0.5113, -0.2325]])\n",
            " |          >>> linear.to(torch.double)\n",
            " |          Linear(in_features=2, out_features=2, bias=True)\n",
            " |          >>> linear.weight\n",
            " |          Parameter containing:\n",
            " |          tensor([[ 0.1913, -0.3420],\n",
            " |                  [-0.5113, -0.2325]], dtype=torch.float64)\n",
            " |          >>> gpu1 = torch.device(\"cuda:1\")\n",
            " |          >>> linear.to(gpu1, dtype=torch.half, non_blocking=True)\n",
            " |          Linear(in_features=2, out_features=2, bias=True)\n",
            " |          >>> linear.weight\n",
            " |          Parameter containing:\n",
            " |          tensor([[ 0.1914, -0.3420],\n",
            " |                  [-0.5112, -0.2324]], dtype=torch.float16, device='cuda:1')\n",
            " |          >>> cpu = torch.device(\"cpu\")\n",
            " |          >>> linear.to(cpu)\n",
            " |          Linear(in_features=2, out_features=2, bias=True)\n",
            " |          >>> linear.weight\n",
            " |          Parameter containing:\n",
            " |          tensor([[ 0.1914, -0.3420],\n",
            " |                  [-0.5112, -0.2324]], dtype=torch.float16)\n",
            " |  \n",
            " |  train(self, mode=True)\n",
            " |      Sets the module in training mode.\n",
            " |      \n",
            " |      This has any effect only on certain modules. See documentations of\n",
            " |      particular modules for details of their behaviors in training/evaluation\n",
            " |      mode, if they are affected, e.g. :class:`Dropout`, :class:`BatchNorm`,\n",
            " |      etc.\n",
            " |      \n",
            " |      Args:\n",
            " |          mode (bool): whether to set training mode (``True``) or evaluation\n",
            " |                       mode (``False``). Default: ``True``.\n",
            " |      \n",
            " |      Returns:\n",
            " |          Module: self\n",
            " |  \n",
            " |  type(self, dst_type)\n",
            " |      Casts all parameters and buffers to :attr:`dst_type`.\n",
            " |      \n",
            " |      Arguments:\n",
            " |          dst_type (type or string): the desired type\n",
            " |      \n",
            " |      Returns:\n",
            " |          Module: self\n",
            " |  \n",
            " |  zero_grad(self)\n",
            " |      Sets gradients of all model parameters to zero.\n",
            " |  \n",
            " |  ----------------------------------------------------------------------\n",
            " |  Data descriptors inherited from torch.nn.modules.module.Module:\n",
            " |  \n",
            " |  __dict__\n",
            " |      dictionary for instance variables (if defined)\n",
            " |  \n",
            " |  __weakref__\n",
            " |      list of weak references to the object (if defined)\n",
            " |  \n",
            " |  ----------------------------------------------------------------------\n",
            " |  Data and other attributes inherited from torch.nn.modules.module.Module:\n",
            " |  \n",
            " |  dump_patches = False\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JGx795EkTPgh",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "3bd67d0e-1aec-4810-80a5-135790dbf95b"
      },
      "source": [
        "help(nd.norm)"
      ],
      "execution_count": 80,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Help on function norm:\n",
            "\n",
            "norm(data=None, ord=_Null, axis=_Null, out_dtype=_Null, keepdims=_Null, out=None, name=None, **kwargs)\n",
            "    Computes the norm on an NDArray.\n",
            "    \n",
            "    This operator computes the norm on an NDArray with the specified axis, depending\n",
            "    on the value of the ord parameter. By default, it computes the L2 norm on the entire\n",
            "    array. Currently only ord=2 supports sparse ndarrays.\n",
            "    \n",
            "    Examples::\n",
            "    \n",
            "      x = [[[1, 2],\n",
            "            [3, 4]],\n",
            "           [[2, 2],\n",
            "            [5, 6]]]\n",
            "    \n",
            "      norm(x, ord=2, axis=1) = [[3.1622777 4.472136 ]\n",
            "                                [5.3851647 6.3245554]]\n",
            "    \n",
            "      norm(x, ord=1, axis=1) = [[4., 6.],\n",
            "                                [7., 8.]]\n",
            "    \n",
            "      rsp = x.cast_storage('row_sparse')\n",
            "    \n",
            "      norm(rsp) = [5.47722578]\n",
            "    \n",
            "      csr = x.cast_storage('csr')\n",
            "    \n",
            "      norm(csr) = [5.47722578]\n",
            "    \n",
            "    \n",
            "    \n",
            "    Defined in src/operator/tensor/broadcast_reduce_op_value.cc:L350\n",
            "    \n",
            "    Parameters\n",
            "    ----------\n",
            "    data : NDArray\n",
            "        The input\n",
            "    ord : int, optional, default='2'\n",
            "        Order of the norm. Currently ord=1 and ord=2 is supported.\n",
            "    axis : Shape or None, optional, default=None\n",
            "        The axis or axes along which to perform the reduction.\n",
            "          The default, `axis=()`, will compute over all elements into a\n",
            "          scalar array with shape `(1,)`.\n",
            "          If `axis` is int, a reduction is performed on a particular axis.\n",
            "          If `axis` is a 2-tuple, it specifies the axes that hold 2-D matrices,\n",
            "          and the matrix norms of these matrices are computed.\n",
            "    out_dtype : {None, 'float16', 'float32', 'float64', 'int32', 'int64', 'int8'},optional, default='None'\n",
            "        The data type of the output.\n",
            "    keepdims : boolean, optional, default=0\n",
            "        If this is set to `True`, the reduced axis is left in the result as dimension with size one.\n",
            "    \n",
            "    out : NDArray, optional\n",
            "        The output NDArray to hold the result.\n",
            "    \n",
            "    Returns\n",
            "    -------\n",
            "    out : NDArray or list of NDArrays\n",
            "        The output of this function.\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fHSzlRkVUYvm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}